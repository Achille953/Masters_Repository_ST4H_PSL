{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5ca106c0-624f-477e-865a-ed42208dcab6",
      "metadata": {
        "id": "5ca106c0-624f-477e-865a-ed42208dcab6"
      },
      "source": [
        "# L1 Logistic regression for mortality risk prediction on MIMIC-IV data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb2c7b0a-5190-4a32-8075-12e98b0263aa",
      "metadata": {
        "id": "cb2c7b0a-5190-4a32-8075-12e98b0263aa"
      },
      "source": [
        "**Goal**: Predict 1-year mortality for patients following their first adult ICU admission.\n",
        "\n",
        "**Our Model**: We will use the L1-regularized logistic regression (LASSO) model to create a strong, interpretable baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i5b9t0XD4JbW",
      "metadata": {
        "id": "i5b9t0XD4JbW"
      },
      "source": [
        "# ðŸ“‚ **Data Access & Setup**\n",
        "\n",
        "This project uses the **MIMIC-IV v3.1** dataset. Due to the sensitive nature of clinical data and regulation, the raw datasets are not included in this repository.\n",
        "\n",
        "**1. Requesting Access**\n",
        "To run this pipeline, you must have a signed Data Use Agreement (DUA):\n",
        "\n",
        "Training: Complete the [CITI Data or Specimens Researchers training](https://about.citiprogram.org/)\n",
        "\n",
        "PhysioNet: Create an account and request access via the [MIMIC-IV PhysioNet Page](https://physionet.org/content/mimiciv/3.1/)\n",
        "\n",
        "**2. Local Setup**\n",
        "Once access is granted, download the following files from the MIMIC-IV dataset\n",
        "\n",
        "hosp/patients.csv.gz\n",
        "\n",
        "hosp/admissions.csv.gz\n",
        "\n",
        "hosp/diagnoses_icd.csv.gz\n",
        "\n",
        "hosp/procedures_icd.csv.gz\n",
        "\n",
        "icu/icustays.csv.gz\n",
        "\n",
        "**3. Running on Google Colab**\n",
        "If using Google Colab, upload these files to your Google Drive and update the data_path variable at the top of the notebook to point to your Drive folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1192ec41-f128-48b8-9969-824401292302",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1192ec41-f128-48b8-9969-824401292302",
        "outputId": "66b1fc53-93ae-40ce-e895-8f6dbee3d2a1"
      },
      "outputs": [],
      "source": [
        "!pip install lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d830e0b-1aa8-4575-9ba6-4daf646d4120",
      "metadata": {
        "id": "3d830e0b-1aa8-4575-9ba6-4daf646d4120"
      },
      "outputs": [],
      "source": [
        "## Import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_auc_score, classification_report,average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from lifelines import KaplanMeierFitter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf5b9090-7daa-4cf4-9607-3fa36cfd3b8b",
      "metadata": {
        "id": "cf5b9090-7daa-4cf4-9607-3fa36cfd3b8b"
      },
      "source": [
        "# 1. Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1e8a7f-4ab1-4d35-a15f-beb87e5ef9ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1e8a7f-4ab1-4d35-a15f-beb87e5ef9ee",
        "outputId": "db48dcf7-1910-4d32-8c00-a41560359446"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "data_path = '' # write your data path\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    print(\"âœ… Path found! Loading files...\")\n",
        "else:\n",
        "    print(\"âŒ Path still not found. Try running the debug script below.\")\n",
        "\n",
        "patients = pd.read_csv(os.path.join(data_path,'patients.csv.gz'))\n",
        "admissions = pd.read_csv(os.path.join(data_path,'admissions.csv.gz'))\n",
        "icustays = pd.read_csv(os.path.join(data_path,'icustays.csv.gz'))\n",
        "diagnoses = pd.read_csv(os.path.join(data_path,'diagnoses_icd.csv.gz'))\n",
        "procedures = pd.read_csv(os.path.join(data_path,'procedures_icd.csv.gz'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4366e5a-246d-44bc-85e2-96838bd47328",
      "metadata": {
        "id": "d4366e5a-246d-44bc-85e2-96838bd47328"
      },
      "outputs": [],
      "source": [
        "# Convert key columns to datetime objects\n",
        "# This is crucial for temporal calculations\n",
        "patients['dod'] = pd.to_datetime(patients['dod']) ##date of death\n",
        "admissions['admittime'] = pd.to_datetime(admissions['admittime'])\n",
        "admissions['dischtime'] = pd.to_datetime(admissions['dischtime'])\n",
        "icustays['intime'] = pd.to_datetime(icustays['intime'])\n",
        "icustays['outtime'] = pd.to_datetime(icustays['outtime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac66359d-db46-4ba4-b2ae-6b5fb76a7c21",
      "metadata": {
        "id": "ac66359d-db46-4ba4-b2ae-6b5fb76a7c21"
      },
      "outputs": [],
      "source": [
        "# Get Patient Demographics (Age)\n",
        "# We merge admissions and patients to get age at admission\n",
        "admissions = admissions.merge(patients[['subject_id', 'anchor_age', 'anchor_year', 'dod']], on='subject_id')\n",
        "\n",
        "\n",
        "# Calculate age. Note: This is an approximation based on MIMIC's anchoring.\n",
        "admissions['age_at_admission'] = admissions['anchor_age'] + (pd.to_datetime(admissions['admittime']).dt.year - admissions['anchor_year'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-TM8_br5wGix",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "-TM8_br5wGix",
        "outputId": "a0fa75d2-9088-4fb3-b302-fb6f6d4b65d9"
      },
      "outputs": [],
      "source": [
        "# 1. Count Total Unique Patients\n",
        "num_patients = admissions['subject_id'].nunique()\n",
        "print(f\"Total number of patients: {num_patients}\")\n",
        "\n",
        "# 2. Calculate number of visits (admissions) per patient\n",
        "# We group by subject_id and count unique hospital admission IDs\n",
        "visits_per_patient = admissions.groupby('subject_id')['hadm_id'].nunique()\n",
        "\n",
        "# 3. Calculate Mean and Standard Deviation (Std)\n",
        "mean_visits = visits_per_patient.mean()\n",
        "std_visits = visits_per_patient.std()\n",
        "\n",
        "print(f\"Mean number of visits per patient: {mean_visits:.2f}\")\n",
        "print(f\"Standard deviation of visits: {std_visits:.2f}\")\n",
        "\n",
        "# 4. Plot the distribution using a Log Scale\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(visits_per_patient, bins=50, color='skyblue', edgecolor='black', log=True)\n",
        "\n",
        "plt.title('Distribution of Visits per Patient (Log Scale)')\n",
        "plt.xlabel('Number of Visits')\n",
        "plt.ylabel('Frequency (Log Count)')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "348abfab-334e-486f-aa9f-65b37c1d5bf0",
      "metadata": {
        "id": "348abfab-334e-486f-aa9f-65b37c1d5bf0"
      },
      "source": [
        "# 2. Define the cohort\n",
        "We want only adults, exclude patients who died in the hospital during their first icu visit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79d9fb3f-0cce-43ca-91d3-299a3be9129a",
      "metadata": {
        "id": "79d9fb3f-0cce-43ca-91d3-299a3be9129a"
      },
      "outputs": [],
      "source": [
        "#take only adult\n",
        "adult_admissions = admissions[admissions['age_at_admission'] >= 18]\n",
        "\n",
        "# Merge with icustays\n",
        "adult_icu = icustays.merge(adult_admissions, on=['subject_id', 'hadm_id'])\n",
        "\n",
        "# Find the *first* icu stay for each patient\n",
        "adult_icu = adult_icu.sort_values(by='intime')\n",
        "first_icu_stays = adult_icu.groupby('subject_id').first().reset_index()\n",
        "\n",
        "# Exclude patients who died in the hospital\n",
        "# `deathtime` in the admissions table is the time of in-hospital death\n",
        "cohort = first_icu_stays[first_icu_stays['deathtime'].isnull()].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33657565-8357-462a-85ed-6af378ba9f6d",
      "metadata": {
        "id": "33657565-8357-462a-85ed-6af378ba9f6d"
      },
      "outputs": [],
      "source": [
        "# The index date is the start of their very first adult ICU stay\n",
        "cohort[\"index_date\"] = cohort[\"intime\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53f53d11-703c-44b3-a4b8-92119ec7d452",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53f53d11-703c-44b3-a4b8-92119ec7d452",
        "outputId": "3d857071-b81e-4fcf-93f6-810c28fd5dc8"
      },
      "outputs": [],
      "source": [
        "print(f\"Initial cohort (first adult ICU stay): {len(first_icu_stays)}\")\n",
        "print(f\"Final cohort (after excluding in-hospital deaths): {len(cohort)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5863ce69-aea3-4200-98bc-44ff37209f05",
      "metadata": {
        "id": "5863ce69-aea3-4200-98bc-44ff37209f05"
      },
      "source": [
        "# 3. Define the Label\n",
        "The label is True if the patient died within the 365-day prediction window after the index date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7fb53d0-61b6-40d8-882b-aee854515155",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7fb53d0-61b6-40d8-882b-aee854515155",
        "outputId": "e2486262-a46e-4466-bc53-acfa14ff2f46"
      },
      "outputs": [],
      "source": [
        "cohort[\"time_to_death\"] = (cohort['dod'] - cohort['index_date']).dt.days\n",
        "cohort[\"time_to_death\"] = cohort[\"time_to_death\"].fillna(np.inf)  # alive patients â†’ very large number\n",
        "cohort['label_1yr_mortality'] = (cohort[\"time_to_death\"] <= 365) & (cohort[\"time_to_death\"] > 0)\n",
        "final_cohort = cohort[['subject_id', 'hadm_id', 'index_date', 'label_1yr_mortality']]\n",
        "print(final_cohort.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ntFW6rya3Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "d6ntFW6rya3Q",
        "outputId": "d6e61911-e006-495c-b937-02484e59a8cc"
      },
      "outputs": [],
      "source": [
        "# 1. Calculate the number of deaths (positive cases)\n",
        "num_positive = final_cohort['label_1yr_mortality'].sum()\n",
        "\n",
        "# 2. Calculate the total cohort size (total patients)\n",
        "total_size = len(final_cohort)\n",
        "\n",
        "# 3. Calculate Prevalence\n",
        "prevalence = num_positive / total_size\n",
        "\n",
        "print(f\"--- Cohort Prevalence Analysis ---\")\n",
        "print(f\"Total Patients: {total_size}\")\n",
        "print(f\"Positive Cases (1-yr Mortality): {num_positive}\")\n",
        "print(f\"Prevalence: {prevalence:.2%}\")\n",
        "\n",
        "# Visualize the class imbalance\n",
        "final_cohort['label_1yr_mortality'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "plt.title('Class Balance: 1-Year Mortality')\n",
        "plt.xticks([0, 1], ['Survived', 'Died'], rotation=0)\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b59f297-e3e3-4024-af14-fb20764242a7",
      "metadata": {
        "id": "7b59f297-e3e3-4024-af14-fb20764242a7"
      },
      "source": [
        "# 4. Raw count matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324a2e40-5927-4b43-899b-d3185ce64a12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "324a2e40-5927-4b43-899b-d3185ce64a12",
        "outputId": "044cbaf1-b690-493c-e939-e9bda36ef170"
      },
      "outputs": [],
      "source": [
        "# We merge the diagnoses, procedure, prescription table with our final_cohort\n",
        "\n",
        "cohort_diagnoses = diagnoses.merge(final_cohort[['subject_id', 'hadm_id']], on=['subject_id', 'hadm_id'])\n",
        "cohort_diagnoses[\"features\"] = cohort_diagnoses[\"icd_code\"].values\n",
        "\n",
        "cohort_procedures =procedures.merge(final_cohort[['subject_id', 'hadm_id']], on=['subject_id', 'hadm_id'])\n",
        "cohort_procedures[\"features\"] = cohort_procedures[\"icd_code\"].values\n",
        "\n",
        "\n",
        "# concat these tables\n",
        "cohort_features = pd.concat([cohort_diagnoses[['subject_id', 'hadm_id', \"features\"]],\n",
        "                            cohort_procedures[['subject_id', 'hadm_id', \"features\"]]])\n",
        "cohort_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddb4a0f4-ea8d-4062-b906-ec5d34de118b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddb4a0f4-ea8d-4062-b906-ec5d34de118b",
        "outputId": "99dcbac2-4283-49a4-ac56-adcd99acd12c"
      },
      "outputs": [],
      "source": [
        "# Create the \"Raw Count Matrix\"\n",
        "# We only care about *presence* (binary), not the count, for this baseline\n",
        "# Use pivot_table to create the matrix:\n",
        "# Rows = subject_id, Columns = icd_code, Values = 1 (if present)\n",
        "print(\"Building feature matrix...\")\n",
        "feature_matrix = cohort_features[[\"subject_id\", \"features\"]].pivot_table(\n",
        "    index='subject_id',\n",
        "    columns='features',\n",
        "    aggfunc=lambda x: 1,  # Fill with 1 if the code exists for the patient\n",
        "    fill_value=0          # Fill with 0 otherwise\n",
        ")\n",
        "\n",
        "print(f\"Feature matrix shape: {feature_matrix.shape}\") # (n_patients, n_unique_icd_codes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40cc581e-e14f-4900-bf05-9d412744bbf9",
      "metadata": {
        "id": "40cc581e-e14f-4900-bf05-9d412744bbf9"
      },
      "outputs": [],
      "source": [
        "# Align Features (X) and Labels (y)\n",
        "# Get the labels for the patients in our feature matrix\n",
        "labels = final_cohort.set_index('subject_id').loc[feature_matrix.index]['label_1yr_mortality']\n",
        "\n",
        "X = feature_matrix\n",
        "y = labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14118c2-5b9c-4c1f-a46d-92330bd44d60",
      "metadata": {
        "id": "e14118c2-5b9c-4c1f-a46d-92330bd44d60"
      },
      "source": [
        "# 5. Model training/validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ebf636-6c91-4ac6-bf6b-6d1c12eee045",
      "metadata": {
        "id": "f7ebf636-6c91-4ac6-bf6b-6d1c12eee045"
      },
      "outputs": [],
      "source": [
        "# Split Data into Train and Test Sets ---\n",
        "# This is vital to prevent data leakage and evaluate the model properly\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=1,\n",
        "    stratify=y  # Ensure same outcome prevalence in train/test\n",
        ")\n",
        "\n",
        "# Scikit-learn Pipeline\n",
        "# We use 'liblinear' solver as it's good for L1 penalty.\n",
        "lasso_model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', LogisticRegression(\n",
        "        penalty='l1',\n",
        "        solver='liblinear',\n",
        "        C=0.1,  # This is a hyperparameter you can tune\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train the Model\n",
        "print(\"\\nTraining the LASSO model...\")\n",
        "lasso_model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0957d640-98bb-4d70-8ab6-47337ef9625d",
      "metadata": {
        "id": "0957d640-98bb-4d70-8ab6-47337ef9625d"
      },
      "outputs": [],
      "source": [
        "# Evaluate on Test Set\n",
        "y_pred_proba = lasso_model.predict_proba(X_test)[:, 1]\n",
        "auroc = roc_auc_score(y_test, y_pred_proba)\n",
        "auprc = average_precision_score(y_test, y_pred_proba)\n",
        "print(f\"Test Set AUROC: {auroc:.4f}\")\n",
        "print(f\"Test Set AUPRC: {auprc:.4f}\")\n",
        "\n",
        "# Show a classification report\n",
        "y_pred = lasso_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=['No Mortality', 'Mortality']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ec8dc9c-7a57-44f5-ace7-dd916e6c9f72",
      "metadata": {
        "id": "7ec8dc9c-7a57-44f5-ace7-dd916e6c9f72"
      },
      "source": [
        "# 6. Model interpretation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e67ecc0-a25d-4750-912a-bced21424e6b",
      "metadata": {
        "id": "2e67ecc0-a25d-4750-912a-bced21424e6b"
      },
      "outputs": [],
      "source": [
        "# Get the trained model and feature names\n",
        "model = lasso_model.named_steps['model']\n",
        "features = X_train.columns\n",
        "\n",
        "# Create a DataFrame of features and their coefficients\n",
        "coefficients = pd.DataFrame({\n",
        "    'feature': features,\n",
        "    'coefficient': model.coef_[0]\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SI41aIjQ2x6R",
      "metadata": {
        "id": "SI41aIjQ2x6R"
      },
      "outputs": [],
      "source": [
        "# 1. Extract coefficients from the model inside the pipeline\n",
        "trained_model = lasso_model.named_steps['model']\n",
        "feature_names = X.columns  # ICD codes\n",
        "\n",
        "# 2. Create a DataFrame for importance\n",
        "importance_df = pd.DataFrame({\n",
        "    'icd_code': feature_names,\n",
        "    'coefficient': trained_model.coef_[0]\n",
        "})\n",
        "\n",
        "# 3. Merge with d_icd_diagnoses for descriptions\n",
        "# This assumes your d_icd_diagnoses table has 'icd_code' and 'long_title'\n",
        "importance_df = importance_df.merge(\n",
        "    d_icd_diagnoses[['icd_code', 'long_title']],\n",
        "    on='icd_code',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 4. Fill missing titles (in case some codes aren't in the dictionary)\n",
        "importance_df['long_title'] = importance_df['long_title'].fillna(\"Unknown Description\")\n",
        "\n",
        "# 5. Get Top 5 Adverse (Highest positive coefficients)\n",
        "top_adverse = importance_df.sort_values(by='coefficient', ascending=False).head(5)\n",
        "\n",
        "# 6. Get Top 5 Protective (Lowest negative coefficients)\n",
        "top_protective = importance_df.sort_values(by='coefficient', ascending=True).head(5)\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"TOP 5 ADVERSE FEATURES (Highest Risk) ---\")\n",
        "print(top_adverse[['icd_code', 'coefficient', 'long_title']])\n",
        "\n",
        "print(\"\\n TOP 5 PROTECTIVE FEATURES (Lowest Risk) ---\")\n",
        "print(top_protective[['icd_code', 'coefficient', 'long_title']])\n",
        "\n",
        "# 7. Check Sparsity (How many features were zeroed out by L1?)\n",
        "num_zero = (importance_df['coefficient'] == 0).sum()\n",
        "print(f\"\\nSparsity: {num_zero} out of {len(importance_df)} features were zeroed out by the L1 penalty.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8070ed9f-9a8f-44f7-be20-45fbcd0ec8b0",
      "metadata": {
        "id": "8070ed9f-9a8f-44f7-be20-45fbcd0ec8b0"
      },
      "source": [
        "# 7. Patient Stratification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b6400d-4fbb-4bd8-91c3-f5aa7840252a",
      "metadata": {
        "id": "46b6400d-4fbb-4bd8-91c3-f5aa7840252a"
      },
      "outputs": [],
      "source": [
        "# Stratify Patients\n",
        "print(\"\\n--- Risk Stratification ---\")\n",
        "test_results = pd.DataFrame({\n",
        "    'true_label': y_test,\n",
        "    'predicted_prob': y_pred_proba\n",
        "})\n",
        "\n",
        "# Define risk groups based on predicted probability\n",
        "quantile_threshold = test_results['predicted_prob'].quantile(0.75)\n",
        "test_results['risk_group'] = 'Low Risk'\n",
        "test_results.loc[test_results['predicted_prob'] >= quantile_threshold, 'risk_group'] = 'High Risk'\n",
        "\n",
        "# Compare actual mortality rates between groups\n",
        "stratification_summary = test_results.groupby('risk_group')['true_label'].agg(['mean', 'count'])\n",
        "stratification_summary = stratification_summary.rename(columns={'mean': 'actual_mortality_rate'})\n",
        "\n",
        "print(stratification_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f14a130d-d422-4d6b-b24a-19f31af4bc2e",
      "metadata": {
        "id": "f14a130d-d422-4d6b-b24a-19f31af4bc2e"
      },
      "source": [
        "# 8. Bonus: survival curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8304795d-0a33-44fd-8383-7255dcaff9c8",
      "metadata": {
        "id": "8304795d-0a33-44fd-8383-7255dcaff9c8"
      },
      "outputs": [],
      "source": [
        "# Convert 1-year mortality label to integer (0 = alive, 1 = died)\n",
        "cohort['event_observed'] = cohort['label_1yr_mortality'].values.astype(int)\n",
        "\n",
        "# Define the duration for Kaplan-Meier:\n",
        "# - If patient died within 1 year, use actual time to death\n",
        "# - If patient survived, censor at 365 days\n",
        "cohort['duration'] = np.where(\n",
        "    cohort['label_1yr_mortality'].values,\n",
        "    cohort['time_to_death'].values,\n",
        "    365\n",
        ")\n",
        "\n",
        "# Ensure no duration is less than 1 day (KMF cannot handle zero duration)\n",
        "cohort['duration'] = cohort['duration'].clip(lower=1)\n",
        "\n",
        "# Merge the survival info with model predictions for plotting\n",
        "merge_results = test_results.join(\n",
        "    cohort[[\"subject_id\", 'event_observed', \"duration\"]].set_index(\"subject_id\")\n",
        ")\n",
        "\n",
        "# Create a Kaplan-Meier fitter and plotting axis\n",
        "kmf = KaplanMeierFitter()\n",
        "ax = plt.subplot(111)\n",
        "\n",
        "\n",
        "# High-risk group\n",
        "high_risk_data = merge_results[merge_results['risk_group'] == 'High Risk']\n",
        "T_high = high_risk_data['duration']          # durations for high-risk patients\n",
        "E_high = high_risk_data['event_observed']    # event indicators (0/1)\n",
        "kmf.fit(T_high, event_observed=E_high, label='High Risk (Model)')\n",
        "kmf.plot_survival_function(ax=ax)            # plot high-risk survival curve\n",
        "\n",
        "\n",
        "# Low-risk group\n",
        "low_risk_data = merge_results[merge_results['risk_group'] == 'Low Risk']\n",
        "T_low = low_risk_data['duration']            # durations for low-risk patients\n",
        "E_low = low_risk_data['event_observed']      # event indicators (0/1)\n",
        "kmf.fit(T_low, event_observed=E_low, label='Low Risk (Model)')\n",
        "kmf.plot_survival_function(ax=ax)            # plot low-risk survival curve\n",
        "\n",
        "\n",
        "plt.title('Survival Plot by Predicted Risk Group')\n",
        "plt.xlabel('Days After ICU Discharge (Prediction Window)')\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.xlim(0, 365)  # Limit x-axis to 1-year window\n",
        "plt.ylim(0.5, 1.0)  # Zoom in on region of interest to see separation\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
