{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "29f1f7fd",
      "metadata": {
        "id": "29f1f7fd"
      },
      "source": [
        "# Word2Vec for Clinical Codes Embedding & Logistic Regression 1-year mortality prediction\n",
        "\n",
        "**Goal**: Move from sparse raw counts to **dense, meaningful embeddings** of medical codes.\n",
        "\n",
        "Train our own medical Word2Vec model\n",
        "\n",
        "Evaluate embeddings in 3 ways (intrinsic, visualization, extrinsic)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“‚ **Data Access & Setup**\n",
        "\n",
        "This project uses the **MIMIC-IV v3.1** dataset. Due to the sensitive nature of clinical data and regulation, the raw datasets are not included in this repository.\n",
        "\n",
        "**1. Requesting Access**\n",
        "To run this pipeline, you must have a signed Data Use Agreement (DUA):\n",
        "\n",
        "Training: Complete the [CITI Data or Specimens Researchers training](https://about.citiprogram.org/)\n",
        "\n",
        "PhysioNet: Create an account and request access via the [MIMIC-IV PhysioNet Page](https://physionet.org/content/mimiciv/3.1/)\n",
        "\n",
        "**2. Local Setup**\n",
        "Once access is granted, download the following files and place them in a folder named data/ in the root of this project:\n",
        "\n",
        "hosp/patients.csv.gz\n",
        "\n",
        "hosp/admissions.csv.gz\n",
        "\n",
        "hosp/diagnoses_icd.csv.gz\n",
        "\n",
        "hosp/procedures_icd.csv.gz\n",
        "\n",
        "icu/icustays.csv.gz\n",
        "\n",
        "**3. Running on Google Colab**\n",
        "If using Google Colab, upload these files to your Google Drive and update the data_path variable at the top of the notebook to point to your Drive folder."
      ],
      "metadata": {
        "id": "N3AOMaYcNE7R"
      },
      "id": "N3AOMaYcNE7R"
    },
    {
      "cell_type": "markdown",
      "id": "220bae82",
      "metadata": {
        "id": "220bae82"
      },
      "source": [
        "## 0. Install & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5699048",
      "metadata": {
        "id": "e5699048"
      },
      "outputs": [],
      "source": [
        "!pip install -q gensim scikit-learn pandas numpy matplotlib seaborn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "216e849c",
      "metadata": {
        "id": "216e849c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm # A nice progress bar\n",
        "tqdm.pandas()\n",
        "\n",
        "# Traditional ML\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import roc_auc_score, classification_report, average_precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Embedding specific\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Visualization\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7112c325",
      "metadata": {
        "id": "7112c325"
      },
      "source": [
        "## 1. The Problem with Traditional Representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4cdc35",
      "metadata": {
        "id": "5b4cdc35"
      },
      "outputs": [],
      "source": [
        "codes = [\n",
        "    ['250001'], # Type 1 diabetes\n",
        "    ['250000'], # Type 2 diabetes\n",
        "    ['R51']  # Headache\n",
        "]\n",
        "# sklearn's OneHotEncoder\n",
        "ohe = OneHotEncoder(sparse_output=False).fit(codes)\n",
        "vec = ohe.transform(codes)\n",
        "\n",
        "# check the cosine similarity\n",
        "print(\"Cosine similarity with one-hot:\")\n",
        "print(f\"  Type1 DM vs Type2 DM = {cosine_similarity(vec[0:1], vec[1:2])[0][0]:.3f}\")\n",
        "print(f\"  Type1 DM vs Headache = {cosine_similarity(vec[0:1], vec[2:3])[0][0]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06d01f44",
      "metadata": {
        "id": "06d01f44"
      },
      "source": [
        "## 2. Build MIMIC-IV Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e32c97e-700b-4fa1-b5c8-434c9f58b8d1",
      "metadata": {
        "id": "4e32c97e-700b-4fa1-b5c8-434c9f58b8d1"
      },
      "source": [
        "We will load all codes, group them by `hadm_id`, and create a list-of-lists. This will be our corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b96772b",
      "metadata": {
        "id": "8b96772b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "DATA_PATH = '' # write your data path\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    print(\"âœ… Path found! Loading files...\")\n",
        "else:\n",
        "    print(\"âŒ Path still not found. Try running the debug script below.\")\n",
        "\n",
        "diag = pd.read_csv(os.path.join(DATA_PATH, \"diagnoses_icd.csv.gz\"))\n",
        "proc = pd.read_csv(os.path.join(DATA_PATH, \"procedures_icd.csv.gz\"))\n",
        "\n",
        "diag = diag[['hadm_id', 'icd_code']].rename(columns={'icd_code': 'code'})\n",
        "proc = proc[['hadm_id', 'icd_code']].rename(columns={'icd_code': 'code'})\n",
        "\n",
        "all_codes = pd.concat([diag, proc]).dropna()\n",
        "corpus_df = all_codes.groupby('hadm_id')['code'].apply(list)\n",
        "\n",
        "# Convert the pandas Series to a simple list of lists\n",
        "corpus = corpus_df.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_sentences = len(corpus)\n",
        "num_words = sum(len(x) for x in corpus)\n",
        "\n",
        "vocabulary = set(code for admission in corpus for code in admission)\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "print(f\"  Number of Sentences (Admissions): {num_sentences:,}\")\n",
        "print(f\"  Total Number of Words (Codes):    {num_words:,}\")\n",
        "print(f\"  Vocabulary Size (Unique Codes):   {vocab_size:,}\")"
      ],
      "metadata": {
        "id": "xXnRKEvSfYiF"
      },
      "id": "xXnRKEvSfYiF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ec325105",
      "metadata": {
        "id": "ec325105"
      },
      "source": [
        "## 3. Train Med2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caaf2035-3e7e-4dda-ae4b-5a5332eb08e2",
      "metadata": {
        "id": "caaf2035-3e7e-4dda-ae4b-5a5332eb08e2"
      },
      "source": [
        "Now that we have our corpus, we can train a Word2Vec model using gensim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f69c4a5b",
      "metadata": {
        "collapsed": true,
        "id": "f69c4a5b"
      },
      "outputs": [],
      "source": [
        "model_file = \"med2vec_mimic4.w2v\"\n",
        "\n",
        "if not os.path.exists(model_file):\n",
        "    print(\"Training model... (~10 min)\")\n",
        "    model = Word2Vec(\n",
        "        sentences=corpus,\n",
        "        vector_size=100,\n",
        "        window=5,\n",
        "        sg=1,\n",
        "        negative=10,\n",
        "        min_count=5,\n",
        "        epochs=10,\n",
        "        workers=os.cpu_count()-1,\n",
        "        seed=42\n",
        "    )\n",
        "    model.save(model_file)\n",
        "else:\n",
        "    model = Word2Vec.load(model_file)\n",
        "\n",
        "#The trained word vectors are stored in a KeyedVectors instance, as model.wv\n",
        "wv = model.wv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a3da8b",
      "metadata": {
        "id": "26a3da8b"
      },
      "source": [
        "## 4. Intrinsic Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d883382d",
      "metadata": {
        "id": "d883382d"
      },
      "outputs": [],
      "source": [
        "# Load official code â†’ name mappings\n",
        "d_diag = pd.read_csv(os.path.join(DATA_PATH, \"d_icd_diagnoses.csv.gz\"))\n",
        "d_proc = pd.read_csv(os.path.join(DATA_PATH, \"d_icd_procedures.csv.gz\"))\n",
        "\n",
        "# Create dictionaries\n",
        "diag_map = dict(zip(d_diag['icd_code'], d_diag['long_title']))\n",
        "proc_map = dict(zip(d_proc['icd_code'], d_proc['long_title']))\n",
        "\n",
        "\n",
        "def code_to_name(code):\n",
        "    if code in diag_map:\n",
        "        return diag_map[code][:70]  # truncate for display\n",
        "    if code in proc_map:\n",
        "        return proc_map[code][:70]\n",
        "    return code  # fallback\n",
        "\n",
        "# Enhanced similar() function with names\n",
        "def similar(code, n=8):\n",
        "    if code not in wv:\n",
        "        print(f\"'{code}' not in vocabulary\")\n",
        "        return\n",
        "    print(f\"\\nMost similar to {code}  |  {code_to_name(code)}\")\n",
        "    print(\"â”€\" * 90)\n",
        "    for w, s in wv.most_similar(code, topn=n):\n",
        "        name = code_to_name(w)\n",
        "        print(f\"  {w:10}  {s:.4f}  |  {name}\")\n",
        "\n",
        "# Show results\n",
        "similar('25000')   # Type 2 diabetes mellitus\n",
        "similar('25001')   # Type 1 diabetes mellitus\n",
        "similar('I10')     # Essential hypertension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30778707",
      "metadata": {
        "id": "30778707"
      },
      "source": [
        "## 5. PCA Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8f77875-9041-4c82-b505-c2f017b88418",
      "metadata": {
        "id": "c8f77875-9041-4c82-b505-c2f017b88418"
      },
      "outputs": [],
      "source": [
        "vocab = list(wv.key_to_index.keys())\n",
        "X = wv[vocab]\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_2d = pca.fit_transform(X)\n",
        "\n",
        "\n",
        "vis_df = pd.DataFrame({\n",
        "    'code': vocab,\n",
        "    'x': X_2d[:, 0],\n",
        "    'y': X_2d[:, 1],\n",
        "    'name': [code_to_name(c) for c in vocab],\n",
        "    'icd': ['ICD-10' if c and c[0].isalpha() else 'ICD-9' for c in vocab]\n",
        "\n",
        "})\n",
        "\n",
        "#Define clinical groups\n",
        "diabetes_codes     = [c for c in vocab if c.startswith('250') or c.startswith(('E08','E09','E10','E11','E13'))]\n",
        "hypertension_codes = [c for c in vocab if c.startswith('401') or c.startswith(('I10','I11','I12','I13','I15'))]\n",
        "breast_cancer_codes = [c for c in vocab if c.startswith(('174','175')) or c.startswith('C50')]\n",
        "heart_failure_codes = [c for c in vocab if c.startswith('428') or c.startswith('I50')]\n",
        "\n",
        "\n",
        "# Assign groups\n",
        "vis_df['group'] = 'Other'\n",
        "vis_df.loc[vis_df['code'].isin(diabetes_codes), 'group'] = 'Diabetes'\n",
        "vis_df.loc[vis_df['code'].isin(hypertension_codes), 'group'] = 'Hypertension'\n",
        "vis_df.loc[vis_df['code'].isin(breast_cancer_codes), 'group'] = 'Breast Cancer'\n",
        "vis_df.loc[vis_df['code'].isin(heart_failure_codes), 'group'] = 'Heart Failure'\n",
        "\n",
        "# Color palette\n",
        "palette = {\n",
        "    'Other': 'lightgray',\n",
        "    'Diabetes': '#d62728',          # red\n",
        "    'Hypertension': '#1f77b4',      # blue\n",
        "    'Breast Cancer': '#ff7f0e',     # orange\n",
        "    'Heart Failure': '#2ca02c',     # green\n",
        "    'Key Medications': '#9467bd'    # purple\n",
        "}\n",
        "\n",
        "## Define type of codes\n",
        "proc_set = d_proc['icd_code'].unique().tolist()\n",
        "diag_set = d_diag['icd_code'].unique().tolist()\n",
        "\n",
        "def def_code_type(x):\n",
        "    if x in diag_set:\n",
        "        return \"Diagnosis\"\n",
        "    elif x in proc_set:\n",
        "        return \"Procedures\"\n",
        "    else:\n",
        "        return \"Other\"\n",
        "vis_df['type'] = vis_df[\"code\"].apply(def_code_type)\n",
        "\n",
        "\n",
        "\n",
        "# Plot codes of interest\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.scatterplot(\n",
        "    data=vis_df[vis_df['group'] == 'Other'],\n",
        "    x='x', y='y',\n",
        "    color='lightgray', alpha=0.4, s=50, label='Other codes'\n",
        ")\n",
        "\n",
        "sns.scatterplot(\n",
        "    data=vis_df[vis_df['group'] != 'Other'],\n",
        "    x='x', y='y',\n",
        "    hue='group',\n",
        "    palette=palette,\n",
        "    s=80,\n",
        "    edgecolor='black',\n",
        "    linewidth=0.8\n",
        ")\n",
        "\n",
        "plt.title('Med2Vec Embeddings')\n",
        "plt.xlabel(f'PC1')\n",
        "plt.ylabel(f'PC2')\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', title='Clinical Group')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82975027-dd00-4d82-a053-182abbb5469d",
      "metadata": {
        "id": "82975027-dd00-4d82-a053-182abbb5469d"
      },
      "outputs": [],
      "source": [
        "# Plot colored by code type\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.scatterplot(data=vis_df, x='x', y='y', hue='type', s=50, alpha=0.8)\n",
        "\n",
        "plt.title('Med2Vec Embeddings')\n",
        "plt.xlabel(f'PC1')\n",
        "plt.ylabel(f'PC2')\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', title='Clinical Group')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d27d546b-25bd-4d81-b123-e5f56829f1d8",
      "metadata": {
        "id": "d27d546b-25bd-4d81-b123-e5f56829f1d8"
      },
      "outputs": [],
      "source": [
        "# Plot colored by code vocabulary\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.scatterplot(data=vis_df, x='x', y='y', hue='icd', s=50, alpha=0.8)\n",
        "\n",
        "plt.title('Med2Vec Embeddings')\n",
        "plt.xlabel(f'PC1')\n",
        "plt.ylabel(f'PC2')\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', title='Clinical Group')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_95 = PCA(n_components=0.95)\n",
        "X_reduced = pca_95.fit_transform(X)\n",
        "\n",
        "n_components_95 = pca_95.n_components_\n",
        "total_dims = X.shape[1]\n",
        "\n",
        "print(f\"Original Dimensions: {total_dims}\")\n",
        "print(f\"Components needed for 95% variance: {n_components_95}\")\n",
        "print(f\"Percentage of dimensions utilized: {n_components_95/total_dims:.1%}\")\n",
        "\n",
        "# Cumulative Variance\n",
        "pca_full = PCA().fit(X)\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(np.cumsum(pca_full.explained_variance_ratio_))\n",
        "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Explained Variance')\n",
        "plt.axvline(x=n_components_95, color='r', linestyle='--')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('PCA Cumulative Variance')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uuDAoxFZG1EE"
      },
      "id": "uuDAoxFZG1EE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a1d35be5",
      "metadata": {
        "id": "a1d35be5"
      },
      "source": [
        "## 6. Extrinsic Evaluation: LR 1-Year Mortality Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbc35b24",
      "metadata": {
        "id": "dbc35b24"
      },
      "outputs": [],
      "source": [
        "# Rebuild exact same cohort as previous notebook (L1-LR 1-year mortality prediction)\n",
        "patients = pd.read_csv(os.path.join(DATA_PATH, \"patients.csv.gz\"))\n",
        "admissions = pd.read_csv(os.path.join(DATA_PATH, \"admissions.csv.gz\"))\n",
        "icustays = pd.read_csv(os.path.join(DATA_PATH, \"icustays.csv.gz\"))\n",
        "\n",
        "for df in [patients, admissions, icustays]:\n",
        "    for col in df.columns:\n",
        "        if 'time' in col.lower() or col == 'dod':\n",
        "            df[col] = pd.to_datetime(df[col])\n",
        "\n",
        "adm = admissions.merge(patients[['subject_id','anchor_age','anchor_year','dod']], on='subject_id')\n",
        "adm['age'] = adm['anchor_age'] + (adm['admittime'].dt.year - adm['anchor_year'])\n",
        "\n",
        "#Keep adults and exclude patients dead in first hospital admin\n",
        "icu = icustays.merge(adm[adm['age'] >= 18], on=['subject_id','hadm_id'])\n",
        "first_stay = icu.sort_values('intime').groupby('subject_id').first().reset_index()\n",
        "cohort = first_stay[first_stay['deathtime'].isna()].copy()\n",
        "cohort['days_to_death'] = (cohort['dod'] - cohort['outtime']).dt.days\n",
        "cohort['label'] = ((cohort['days_to_death'] <= 365) & (cohort['days_to_death'] > 0)).astype(int)\n",
        "\n",
        "data = cohort[['subject_id', 'hadm_id', 'label']]\n",
        "print(f\"Final cohort: {len(data)} patients\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96148614-8462-4a3f-9344-f1530b580b02",
      "metadata": {
        "id": "96148614-8462-4a3f-9344-f1530b580b02"
      },
      "outputs": [],
      "source": [
        "corpus = corpus_df.to_dict()\n",
        "def patient_vector(hadm):\n",
        "    codes = corpus.get(hadm, [])          # corpus must be dict\n",
        "    vecs = [wv[c] for c in codes if c in wv]\n",
        "    if vecs:\n",
        "        return np.mean(vecs, axis=0)\n",
        "    else:\n",
        "        return np.zeros(wv.vector_size)\n",
        "\n",
        "# Build X: ensure order matches data['hadm_id']\n",
        "X = np.stack(data['hadm_id'].progress_apply(patient_vector).values)\n",
        "y = data['label'].values\n",
        "\n",
        "# Diagnostic: fraction of all-zero vectors\n",
        "n_zero = np.sum(np.all(X == 0, axis=1))\n",
        "print(f\"Patient vectors: {X.shape}, zero vectors: {n_zero} ({n_zero/len(X):.2%})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "model = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "auroc = roc_auc_score(y_test, y_probs)\n",
        "auprc = average_precision_score(y_test, y_probs)\n",
        "\n",
        "print(f\"Results for Patient Embeddings (Mortality Prediction):\")\n",
        "print(f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(f\"AUROC (Area Under ROC Curve):        {auroc:.4f}\")\n",
        "print(f\"AUPRC (Area Under Precision-Recall): {auprc:.4f}\")\n",
        "print(f\"Baseline AUPRC (Random Guess):       {y.mean():.4f}\")\n",
        "print(f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "\n",
        "# Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# ROC Curve\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
        "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {auroc:.2f})')\n",
        "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.set_title('Receiver Operating Characteristic (ROC)')\n",
        "ax1.legend(loc=\"lower right\")\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# PR Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
        "ax2.plot(recall, precision, color='green', lw=2, label=f'PR (AUC = {auprc:.2f})')\n",
        "ax2.axhline(y=y.mean(), color='navy', linestyle='--', label=f'Baseline ({y.mean():.2f})')\n",
        "ax2.set_xlabel('Recall (Sensitivity)')\n",
        "ax2.set_ylabel('Precision (PPV)')\n",
        "ax2.set_title('Precision-Recall Curve')\n",
        "ax2.legend(loc=\"upper right\")\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZfdgNOQxSnc2"
      },
      "id": "ZfdgNOQxSnc2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}